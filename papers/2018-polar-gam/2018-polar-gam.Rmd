---
title: Assessing midsaggital tongue contours in polar coordinates using generalised additive (mixed) models
author: Stefano Coretta
output:
  pdf_document:
    citation_package: natbib
    fig_caption: yes
    highlight: tango
    keep_tex: yes
    latex_engine: xelatex
    number_sections: yes
bibliography: linguistics.bib
biblio-style: unified.bst
header-includes:
- \usepackage{cleveref}
fontsize: 12pt
indent: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.align = "center")
knitr::opts_knit$set(root.dir = normalizePath("../../"))
library(tidyverse)
theme_set(theme_minimal())
library(tidymv)
library(rticulate)
library(mgcv)
library(itsadug)
```

```{r read-data, include=FALSE}
stimuli <- read_csv("./papers/2018-polar-gam/datasets/stimuli.csv")

columns <- c(
  "speaker",
  "seconds",
  "rec_date",
  "prompt",
  "label",
  "TT_displacement_sm",
  "TT_velocity",
  "TT_velocity_abs",
  "TD_displacement_sm",
  "TD_velocity",
  "TD_velocity_abs",
  "TR_displacement_sm",
  "TR_velocity",
  "TR_velocity_abs"
)

tongue_it01 <- read_aaa("./papers/2018-polar-gam/datasets/it01-tongue-cart.tsv", columns)  %>%
  na.omit() %>%
  mutate(word = word(prompt, 2)) %>%
  left_join(y = stimuli) %>%
  filter(X < 40, c1_phonation == "voiceless", label %in% c("max_TT", "max_TD")) %>%
  mutate(
    vc_voicing = interaction(vowel, c2_place, c2_phonation),
    vc_voicing = ordered(vc_voicing),
    c2 = factor(c2, levels = c("t", "d", "k", "g"))
  ) %>%
  mutate_if(is.character, as.factor) %>%
  arrange(rec_date, fan_line) %>%
  create_event_start("rec_date")

contrasts(tongue_it01$vc_voicing) <- "contr.treatment"

tongue_it02 <- read_aaa("./papers/2018-polar-gam/datasets/it02-tongue-cart.tsv", columns)  %>%
  na.omit() %>%
  mutate(word = word(prompt, 2)) %>%
  left_join(y = stimuli) %>%
  filter(c1_phonation == "voiceless", label %in% c("max_TT", "max_TD"), fan_line > 5, fan_line < 40) %>%
  mutate(
    vc_voicing = interaction(vowel, c2_place, c2_phonation),
    vc_voicing = ordered(vc_voicing),
    c2 = factor(c2, levels = c("t", "d", "k", "g"))
  ) %>%
  mutate_if(is.character, as.factor) %>%
  arrange(rec_date, fan_line) %>%
  create_event_start("rec_date")

contrasts(tongue_it02$vc_voicing) <- "contr.treatment"

tongue_it03 <- read_aaa("./papers/2018-polar-gam/datasets/it03-tongue-cart.tsv", columns)  %>%
  na.omit() %>%
  mutate(word = word(prompt, 2)) %>%
  left_join(y = stimuli) %>%
  filter(c1_phonation == "voiceless", label %in% c("max_TT", "max_TD"), fan_line < 40) %>%
  mutate(
    vc_voicing = interaction(vowel, c2_place, c2_phonation),
    vc_voicing = ordered(vc_voicing),
    c2 = factor(c2, levels = c("t", "d", "k", "g"))
  ) %>%
  mutate_if(is.character, as.factor) %>%
  arrange(rec_date, fan_line) %>%
  create_event_start("rec_date")

contrasts(tongue_it03$vc_voicing) <- "contr.treatment"

tongue_it04 <- read_aaa("./papers/2018-polar-gam/datasets/it04-tongue-cart.tsv", columns)  %>%
  na.omit() %>%
  mutate(word = word(prompt, 2)) %>%
  left_join(y = stimuli) %>%
  filter(c1_phonation == "voiceless", label %in% c("max_TT", "max_TD"), fan_line < 38) %>%
  mutate(
    vc_voicing = interaction(vowel, c2_place, c2_phonation),
    vc_voicing = ordered(vc_voicing),
    c2 = factor(c2, levels = c("t", "d", "k", "g"))
  ) %>%
  mutate_if(is.character, as.factor) %>%
  arrange(rec_date, fan_line) %>%
  create_event_start("rec_date")

contrasts(tongue_it04$vc_voicing) <- "contr.treatment"
```

# Introduction

<!-- need to say that tongue comes from UTI -->
Since the publication of the seminal paper by @davidson2006, statistical modelling of whole tongue contours obtained with ultrasound imaging has been dominated by the use of Smoothing Splines Analysis of Variance (SSANOVA, \citealt{gu2013}).
These models have greatly advanced our understanding of tongue articulation and speech modelling.
<!-- Some of the limitations of modelling tongue contours with SSANOVA is that separate models are needed for different phonetic contexts even within a single speaker, and that SSANOVA as implemented in most studies does not include random effects (for the importance of random effects in ).
The general difficulty felt with SSANOVA and tongue contours has favoured alternative methods like Principal Component Analysis. -->
On the other hand, a variety of research disciplines is witnessing an increased use of Generalised Additive Models (GAMs) and their mixed-effects counterpart (GAMMs, \citealt{wood2006}), especially when dealing with complex data.
GAMs have being increasingly adopted in linguistics as a means to model dynamic speech data.
<!-- Indeed, @soskuthy2017 explicitly suggests the use of GAMs with tongue contours. -->
This paper introduces an implementation of GAMs with tongue contours using polar coordinates.
The use of polar GAMs is illustrated with ultrasound tongue imaging data comparing voiceless and voiced stops.
The R package `rticulate` has been developed to facilitate the use of the model, and it is briefly introduced here.

## Ultrasound tongue imaging

Ultrasound imaging is a non-invasive technique for obtaining an image of internal organs and other body tissues.
2D ultrasound imaging has been successfully used for imaging sections of the tongue surface (for a review and applications in field settings, see \citealt{gick2002} and \citealt{lulich2018}).
An image of the (2D) tongue surface can be obtained by placing the transducer in contact with the sub-mental triangle (the area under the chin), aligned either with the mid-sagittal or the coronal plane.
The ultrasonic waves propagate from the transducer in a radial fashion through the aperture of the mandible and get reflected when they hit the air above the tongue surface.
This 'echo' is captured by the transducer and translated into an image like the one shown in \Cref{f:uti}.

\begin{figure}
  \centering
  \includegraphics{./img/uti.png}
  \caption{An ultrasound image showing a mid-sagittal view of the tongue. The white curved stripe in the image indicates where the ultrasonic waves have been reflected by the air above the tongue. The tongue surface corresponds to the lower edge of the white stripe. In this image, the tongue tip is located on the right. The green curve approximates the location of the palate.}
  \label{f:uti}
\end{figure}

## Generalised Additive models

Generalised additive models, or GAMs, are a more general form of non-parametric modelling that allows fitting non-linear as well as linear effects, and combine properties of linear and additive modelling \citep{hastie1986}.
GAMs are built with smoothing splines (like SSANOVA, see \citealt{helwig2016}), which are defined piecewise with a set (the *basis*) of polynomial functions (the *basis functions*).
When fitting GAMs, the smoothing splines try to maximise the fit to the data while being constrained by a smoothing penalty (usually estimated from the data itself).
Such penalisation constitutes a guard against overfitting.
GAMs are thus powerful and flexible models that can deal with non-linear data efficiently.
Moreover, GAMs have a mixed-effect counterpart, Generalised Additive Mixed Models (GAMMs), in which random effects can be included (for a technical introduction to GAM(M)s, see \citet{zuur2012} and \citet{wood2017}).
GAMs can offer relief from issues of autocorrelation between points of the contour (given that points close to each other are not independent from one another).
For example, GAMs can fit separate smooths to individual contours, or a first-order autoregression model can be included which tries to account for the autocorrelation between each point in the contour and the one following it.
Tongue contours obtained from ultrasound imaging lend themselves to be efficiently modelled using GAM(M)s.

## Polar coordinates

\citet{mielke2015} and \citet{heyne2015a, heyne2015} have shown that using polar coordinates of tongue contours rather than cartesian coordinates brings several benefits, among which reduced variance at the contour edges.
Points in a polar coordinate system are defined by pairs of radial and angular values.
The point is describes with a radius, which corresponds to the radial distance from the origin, and the angle from the reference radius.
Tongue contours, due to their shape, tend to have increasing slope at the left and right edges, in certain cases tending to become almost completely vertical.
The almost verticality of the contours has the effect of increasing the variance of the fitted contours (and hence increased confidence intervals), and in some cases it can even generate uninterpretable curves.

This issue is illustrated in \Cref{f:smooths}.
The *x* and *y* axes are the *x* and *y* cartesian coordinates in millimeters.
The plot shows LOESS smooths superimposed on the points of the individual tongue contours of an Italian speaker (IT01, see \Cref{s:data}).
These contours refer to the mid-sagittal shape of the tongue during the closure of four consonants (/t, d, k, g/) preceded by one of three vowels (/a, o, u/).
The tip of the tongue is on the right-end side of each panel.
Focussing on the smooths, it can be noticed that the smooths in the contexts of the vowel /u/ diverge substantially from the true contours (as inferred by the points).
In the contexts of velar consonants and the other two vowels, one could say that the back/root of the tongue is somewhat flatted out relative to the actual contours.
These artefacts of smoothing happen because, especially in the right-edge of these particular contours, the slope of the curve increases in such a way that at times the curve bends under itself (see for example the context /ug/, when *x* is between -30 and -20).
Since those points on the bend share the *x* value, the smooth just averages across the *y* values of those points.

```{r smooths, include=TRUE, fig.cap = "Estimated tongue contours of IT01 depending on C2 place, vowel and C2 voicing.", fig.lp="f:", out.extra="width=\\linewidth"}
tongue_it01 %>%
  ggplot(aes(X, Y)) +
  geom_point(alpha = 0.05) +
  geom_smooth(aes(colour = vowel), method = "loess") +
  coord_fixed() +
  facet_grid(vowel ~ c2) +
  theme(legend.position = "none")
```

\Cref{f:paths} shows a better way of representing individual tongue contours.
In these plots, the points of each contour are connected sequentially by a line, rather than smoothed over.
The parts in which the contours bends over are kept and visualised correctly

```{r paths, include=TRUE, fig.cap = "Estimated tongue contours of IT01 depending on C2 place, vowel and C2 voicing.", fig.lp="f:", out.extra="width=\\linewidth"}
tongue_it01 %>%
  ggplot(aes(X, Y)) +
  geom_path(aes(group = rec_date, colour = vowel), alpha = 0.5) +
  coord_fixed() +
  facet_grid(vowel ~ c2) +
  theme(legend.position = "none")
```
These figures illustrate that using cartesian coordinates for modelling can introduce smoothing artefacts which in turn can negatively affect the model output.
When tongue contours are expressed with polar coordinates, on the other hand, the variance is reduced and the fitted contours generally reflect more closely the underlying tongue shape.
Mielke has implemented a series of R [@r-core-team2018] functions for fitting polar SSANOVAs to tongue contours.
While model fitting is achieved using polar coordinates, plotting of the model output is subsequently obtained by reconverting the coordinates to cartesian.
The method introduce in this paper is based on Mielke's implementation applied to GAMs.

# Polar GAM(M)s

GAMs fitted to tongue contours in polar coordinates are introduced here.
A polar GAM is constructed as follows.
The outcome variable of the model are the radial coordinates, while a smooth term over the angular coordinates is the predictor which takes care of modelling the curved shape of the contour.
Other predictors, such as consonant or vowel type, speech rate, or random effects, can be also included.
The model returns fitted smooths with polar coordinates as units.
The predicted polar coordinates can be derived from the fitted smooths and converted into a cartesian coordinate system (centred on the origin of the polar system) for plotting.
A simple example with data from one speaker will illustrate how to fit polar GAMs with the R package `rticulate`.
The following section gives information on the ultrasonic system used for data collection and on how the data has been processed, before moving onto model fitting itself.

<!-- The function `polar_gam()` accepts cartesian coordinates, which are converted into polar using a user specified origin or the origin estimated from the data.
The polar origin is either known or estimated from the data, depending on the ultrasonic system used.
The GAM is fitted on the polar coordinates and the predicted values are converted back to cartesian using the same origin for plotting. -->

## Data collection and processing
\label{s:data}

Synchronised audio and ultrasound tongue imaging data have been recorded from 4 speakers of Italian while reading a series of controlled sentences.
An Articulate Instruments Ltd™ set-up was used for this study.
The ultrasonic data was collected through a TELEMED Echo Blaster 128 unit with a TELEMED C3.5/20/128Z-3 ultrasonic transducer (20mm radius, 2-4 MHz).
A synchronisation unit (P-Stretch) was plugged into the Echo Blaster unit and used for automatic audio/ultrasound synchronisation.
A FocusRight Scarlett Solo pre-amplifier and a Movo LV4-O2 Lavalier microphone were used for audio recording.
The acquisition of the ultrasonic and audio signals was achieved with the software Articulate Assistant Advanced (AAA, v2.17.2) running on a Hawlett-Packard ProBook 6750b laptop with Microsoft Windows 7.
Stabilisation of the ultrasonic transducer was ensured by using the metallic headset produced by Articulate Instruments Ltd™ (\citeyear{articulate2008}).

Before the reading task, the participant's occlusal plane was obtained using a bite plate [@scobbie2011].
The participants read nonce words embedded in the frame sentence *Dico \_\_\_ lentamente* 'I say \_\_\_ slowly'.
The words follow the structure C\textsubscript{1}V́\textsubscript{1}C\textsubscript{2}V\textsubscript{2}, where C\textsubscript{1} = /p/, V\textsubscript{1} = /a, o, u/, C\textsubscript{2} = /t, d, k, g/, and V\textsubscript{2} = V\textsubscript{1}.
Each speaker repeated the stimuli six times.

Spline curves were fitted to the visible tongue contours using the AAA automatic tracking function.
Manual correction was applied in those cases that showed clear tracking errors.
The time of maximum tongue displacement within consonant closure was then calculated in AAA following the method in @strycharczuk2015.
A fan-like frame consisting of 42 equidistant radial lines was used as the coordinate system.
The origin of the 42 fan-lines coincides with the centre of the ultrasonic probe, such that each fan-line is parallel to the direction of the ultrasonic signal.
Tongue displacement was thus calculated as the displacement of the fitted splines along the fan-line vectors.
The time of maximum tongue displacement was the time of greater displacement along the fan-line vector that showed the greatest standard deviation (as assessed manually).
The vector standard deviation search area was restricted to the portion of the contour corresponding to the tongue tip for coronal consonants, and to the portion corresponding to the tongue dorsum for velar consonants.

The cartesian coordinates of the tongue contours were extracted from the ultrasonic data at the time of maximum tongue displacement (always within C2 closure).
The contours were subsequently normalised within speaker by applying offsetting and rotation relative to the participant’s occlusal plane [@scobbie2011].
Each participants' dataset is thus constituted by *x* and *y* coordinates of the tongue contours that define respectively the horizontal and vertical axes.
The horizontal plane is parallel to the speaker's occlusal plane.

## Fitting a polar GAM

GAMs can be fitted in R with the `gam()` function from package `mgcv` [@wood2011; @wood2017].
`bam()` is a more efficient function when the datasets has several hundreds observations.
The package `rticulate` has been developed as a wrapper of the `bam()` function to be used with tongue contours.
The special function `polar_gam()` can fit any specified GAM model to tongue contours coordinates, using the same syntax of `mgcv`.
The function accepts tongue contours either in cartesian or polar coordinates.
In the first case, the coordinates can be transformed into polar before fitting.
If the data is in the AAA fan-like coordinate system, the origin is automatically estimated with the method in \citet{heyne2015a}.
If the data is not exported from AAA, the user can specify the known coordinates of probe origin.
The function `plot_polar_smooths()`, used for plotting the estimated contours, converts the coordinates back into cartesian using the same origin as with GAM fitting.

A GAM in R can be specified with a formula that uses the same syntax of `lme4`, a commonly used package for linear mixed-effects models \citep{bates2015}.
The `mgcv` package allows to specify smoothing spline terms with the function `s()`.
This function takes the term along which a spline is created (for example, time in a time series, or *x*-coordinates in a cartesian system).
Among the arguments of `s()`, the user can select the type of spline (the `bs` argument) and the grouping factor used for comparison (the `by` argument).
For a more in-depth introduction to GAMs in R for linguistics, see \citet{soskuthy2017} and \citet{wieling2017}.

As means of illustration, the following paragraphs will show how to fit a polar GAM with data from one of the 4 Italian speakers.
<!-- show the problem -->
Due to differences in the placement of the probe and in the speakers' anatomy, different portions of the tongue are likely to be imaged across speakers, so that scaling might not be possible (or wise).
For this reason, it is recommended to fit separate models for each participant, rather than aggregate all of the data in a single model.

We can start from a simple model in which we test the effect of C2 place, vowel, and voicing on tongue contours.
`vc_voicing` is an ordered factor that specifies the combination of C2 place, vowel, and voicing.
Modelling different contours for each combination of the three predictors can be achieved by using `vc_voicing` with the `by` argument of the difference smooth, and by including `vc_voicing` as a parametric term.
The following code fits the specified model to the contour data of IT01.
When running the code, the coordinates of the estimated origin used for the conversion to polar coordinates are returned.
The model is fitted by Maximum Likelihood (ML) here to allow model comparison below).

```{r it01-gam, echo=TRUE, cache=TRUE}
it01_gam <- polar_gam(
  Y ~
    vc_voicing +            # parametric term
    s(X) +                  # reference smooth
    s(X, by = vc_voicing),  # difference smooth
  data = tongue_it01,
  method = "ML"
)
```

The function `plot_polar_smooths()` can be used to plot the estimated contours.
The shaded areas around the estimated contours are 95\% confidence intervals.
Note that, differently from SSANOVA, statistical significance can't be assessed from the overlapping (or lack thereof) of the confidence intervals.

```{r it01-gam-plot-code, echo=TRUE, eval=FALSE}
plot_polar_smooths(
  it01_gam,
  X,
  voicing,
  facet_terms = c2_place + vowel,
  # the following splits the factor interaction in the individual terms,
  # so that they can called in the plotting arguments
  split = list(vc_voicing = c("vowel", "c2_place", "voicing"))
) +
  coord_fixed() +
  theme(legend.position = "top")
```

```{r it01-gam-plot, include=TRUE, fig.cap = "Estimated tongue contours of IT01 depending on C2 place, vowel and C2 voicing.", fig.lp="f:", out.extra="width=\\linewidth"}
plot_polar_smooths(
  it01_gam,
  X,
  voicing,
  facet_terms = c2_place + vowel,
  # the following splits the factor interaction in the individual terms, so that
  # they can called in the plotting arguments
  split = list(vc_voicing = c("vowel", "c2_place", "voicing"))
) +
  coord_fixed() +
  theme(legend.position = "top")
```

One way to assess significance of model terms is to compare the ML score of the full model against one without the relevant predictor, using the function `compareML()` from the `itsadug` package.
Both the parametric term and the difference smooth need to be removed in the null model.

```{r it01-gam-0, echo=TRUE, cache=TRUE}
it01_gam_0 <- polar_gam(
  Y ~
    # vc_voicing +            # remove parametric term
    s(X),                     # keep reference smooth
    # s(X, by = vc_voicing),  # remove difference smooth
  data = tongue_it01,
  method = "ML"
)
```

```{r compare-it01, echo=TRUE}
compareML(it01_gam_0, it01_gam)
```

To check which part of the contour differs among conditions, the method recommended in \citet{soskuthy2017} is to plot the difference smooth and check the confidence interval.
The parts of confidence interval that don't include 0 indicate that the difference between contours in that part is significant.
\Cref{f:diff-it01} illustrates the use of difference smooths with the difference smooths of voiceless vs. voiced coronal stops when the vocalic context is /a/ or /u/.
As per usual, the tongue tip is on the right-end side of each plot.
The difference smooths indicate that there is a significant difference along the most anterior part of the tongue (the root and dorsum).
Based on the predicted smooths sown in \Cref{f:it01-gam-plot}, we can argue that, in the context of coronal consonants, the root is more advanced in voiced relateive to voiceless stops (when the vowel is either /a/ or /u/), and that the dorsum is also somewhat retracted in voiced stops if the vowel is /u/.

```{r diff-it01, include=TRUE, fig.cap = "Difference smooth of voiceless vs. voiced stops in the context of /a/ (left) and /u/ (right).", fig.show="hold",fig.lp="f:", out.width=".7\\linewidth", out.height="5cm"}
plot_difference(
  it01_gam,
  X,
  difference = list(vc_voicing = c("a.coronal.voiced", "a.coronal.voiceless"))
) +
  scale_x_reverse() +
  labs(title = "/a/")

plot_difference(
  it01_gam,
  X,
  difference = list(vc_voicing = c("u.coronal.voiced", "u.coronal.voiceless"))
) +
  scale_x_reverse() +
  labs(title = "/u/")
```

As mentioned in the introduction, autocorrelation in the data can produce unwanted patterns in the residuals, which in turn can affect the estimated smooths (and falsely increase certainty about them).
A first-order autoregressive (AR1) model can be included to reduce autocorrelation at lag 1.
\Cref{f:it01-acf} show the autocorrelations in the residuals without and with an AR1 model.
The GAM model with the AR1 correction has lower values of autocorrelations.
In this case, it is thus advisable to perform ML comparison and smooths plotting with models in which an AR1 model has been included.
For a more in-depth treatment of issues related to autocorrelation, see \citet{soskuthy2017}.

```{r it01-gam-ar, cache=TRUE, message=FALSE}
it01_rho <- start_value_rho(it01_gam)

it01_gam_ar <- polar_gam(
  Y ~
    vc_voicing +
    s(X) +
    s(X, by = vc_voicing),
  data = tongue_it01,
  method = "ML",
  rho = it01_rho,
  AR_start = tongue_it01$start.event
)
```

```{r it01-acf, include=TRUE, fig.cap = "Autocorrelation plots of a model fitted without (left) and with (right) a first-order autoregressive model (AR1).", fig.show="hold",fig.lp="f:", out.width=".7\\linewidth", out.height="5cm"}
acf_resid(it01_gam, split_pred = list(tongue_it01$start.event))
acf_resid(it01_gam_ar, split_pred = "start.event")
```

# Comparing tongue contours in voiceless and voiced stops

Mid-sagittal tongue contours at maximum tongue displacement of voiceless and voiced stops have been compared using polar GAMs.
\Cref{f:tongues-it01} to \Cref{f:tongues-it04} show an appreciable degree of variation across speakers and phonological contexts in relation to the differences in tongue shapes between voiceless and voiced stops.
In some speakers and contexts, the tongue root (the left of the tongue contours) is more advanced in voiced stops than in voiceless stops, especially in the context of a coronal C2 and /a/.
Tongue root advancement is a well known mechanism employed to maintain intra-oral pressure below the threshold required for voicing \citep{ohala2011, kent1969, perkell1969, westbury1983, ahn2018}.

The magnitude of the difference in tongue root position in the data reported here is about 2 millimetres.
\citet{kirkham2017} find that the tongue root in +ATR vowels is on average 4 millimetres more advanced than the respective −ATR vowels.
\citet{rothenberg1967} argues, based on modelling, that the tongue root can move forward by a maximum of about 5 mm mid-sagittally.
This movement corresponds to an average volume increase of 18 cm\textsuperscript{2}.
Given these estimates, it can be argued that a 2 mm change reasonably contributes to an appreciable volume increase, also considering that other volume expansion mechanisms can operate along with the advancement of the tongue root (like larynx lowering, slack oral walls, etc.).

```{r it01-gam-ar-2, cache=TRUE, message=FALSE, include=FALSE}
it01_gam_ar_0 <- polar_gam(
  Y ~
    s(X),
  data = tongue_it01,
  method = "ML",
  rho = it01_rho,
  AR_start = tongue_it01$start.event
)

compareML(it01_gam_ar_0, it01_gam_ar)
```

```{r it02-gam-ar, cache=TRUE, message=FALSE, include=FALSE}
it02_gam <- polar_gam(
  Y ~
    vc_voicing +
    s(X) +
    s(X, by = vc_voicing),
  data = tongue_it02,
  method = "ML"
)

it02_rho <- start_value_rho(it02_gam)

it02_gam_ar <- polar_gam(
  Y ~
    vc_voicing +
    s(X) +
    s(X, by = vc_voicing),
  data = tongue_it02,
  method = "ML",
  rho = it02_rho,
  AR_start = tongue_it02$start.event
)

it02_gam_ar_0 <- polar_gam(
  Y ~
    s(X),
  data = tongue_it02,
  method = "ML",
  rho = it02_rho,
  AR_start = tongue_it02$start.event
)

compareML(it02_gam_ar_0, it02_gam_ar)
```

```{r it03-gam-ar, cache=TRUE, message=FALSE, include=FALSE}
it03_gam <- polar_gam(
  Y ~
    vc_voicing +
    s(X) +
    s(X, by = vc_voicing),
  data = tongue_it03,
  method = "ML"
)

it03_rho <- start_value_rho(it03_gam)

it03_gam_ar <- polar_gam(
  Y ~
    vc_voicing +
    s(X) +
    s(X, by = vc_voicing),
  data = tongue_it03,
  method = "ML",
  rho = it03_rho,
  AR_start = tongue_it03$start.event
)

it03_gam_ar_0 <- polar_gam(
  Y ~
    s(X),
  data = tongue_it03,
  method = "ML",
  rho = it03_rho,
  AR_start = tongue_it03$start.event
)

compareML(it03_gam_ar_0, it03_gam_ar)
```

```{r it04-gam-ar, cache=TRUE, message=FALSE, include=FALSE}
it04_gam <- polar_gam(
  Y ~
    vc_voicing +
    s(X) +
    s(X, by = vc_voicing),
  data = tongue_it04,
  method = "ML"
)

it04_rho <- start_value_rho(it04_gam)

it04_gam_ar <- polar_gam(
  Y ~
    vc_voicing +
    s(X) +
    s(X, by = vc_voicing),
  data = tongue_it04,
  method = "ML",
  rho = it04_rho,
  AR_start = tongue_it04$start.event
)

it04_gam_ar_0 <- polar_gam(
  Y ~
    s(X),
  data = tongue_it04,
  method = "ML",
  rho = it04_rho,
  AR_start = tongue_it04$start.event
)

compareML(it04_gam_ar_0, it04_gam_ar)
```

```{r tongues-it01, include=TRUE, fig.cap = "Tongue contours of voiceless and voiced stops in IT01.", fig.lp="f:", out.width=".8\\textwidth"}
plot_polar_smooths(it01_gam_ar, X, voicing, facet_terms = c2_place + vowel, split = list(vc_voicing = c("vowel", "c2_place", "voicing"))) +
  theme(legend.position = "top") +
  labs(x = "", y = "")
```

```{r tongues-it02, include=TRUE, fig.cap = "Tongue contours of voiceless and voiced stops in IT02.", fig.lp="f:", out.width=".8\\textwidth"}
plot_polar_smooths(it02_gam_ar, X, voicing, facet_terms = c2_place + vowel, split = list(vc_voicing = c("vowel", "c2_place", "voicing"))) +
  theme(legend.position = "top") +
  labs(x = "", y = "")
```

```{r tongues-it03, include=TRUE, fig.cap = "Tongue contours of voiceless and voiced stops in IT03.", fig.lp="f:", out.width=".8\\textwidth"}
plot_polar_smooths(it03_gam_ar, X, voicing, facet_terms = c2_place + vowel, split = list(vc_voicing = c("vowel", "c2_place", "voicing"))) +
  theme(legend.position = "top") +
  labs(x = "", y = "")
```

```{r tongues-it04, include=TRUE, fig.cap = "Tongue contours of voiceless and voiced stops in IT04.", fig.lp="f:", out.width=".8\\textwidth"}
plot_polar_smooths(it04_gam_ar, X, voicing, facet_terms = c2_place + vowel, split = list(vc_voicing = c("vowel", "c2_place", "voicing"))) +
  theme(legend.position = "top") +
  labs(x = "", y = "")
```

# Conclusions

Generalised additive (mixed) models (GAMs) can be efficiently used to statistically assess differences in tongue contour shapes as obtained from ultrasound tongue imaging.
This paper showed how GAMs can be fitted to tongue contours in polar coordinates in R with the specialised package `rticulate`.
An example of how GAMs can help modelling differences in tongue contours has been illustrated with data from 4 speakers of Italian in which the mid-sagittal tongue contours of voiceless and voiced stops where compared.
The same general advantages and issues noted in \citet{davidson2006} for SSANOVA apply to polar GAMs.
In particular, while within-speaker normalisation can be achieved by rotation and offsetting of the data relative to a bite plate (as done here), across-speaker normalisation represents a bigger challenge.
Since it can't be deduced with sufficient certainty from the ultrasonic image which part of the tongue is being actually imaged, it is not possible to define fixed anatomical landmarks across speakers that can be used in normalisation.
For this reason it has been recommended here to fit separate models for each speaker.
Future work will explore ways of allowing the user to use data aggregated from multiple speakers while accounting for the uncertainty in which parts of the tongue are imaged.
To conclude, polar GAMs can also be extended to model whole tongue contours differences over time (in other words, how the sectional shape of the tongue changes over time) and 3D tongue surfaces.
