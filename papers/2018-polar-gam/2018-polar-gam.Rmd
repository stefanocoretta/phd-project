---
title: Assessing midsaggital tongue contours in polar coordinates using generalised additive (mixed) models
author: Stefano Coretta
output:
  pdf_document:
    citation_package: natbib
    keep_tex: yes
    latex_engine: xelatex
    number_sections: yes
bibliography: linguistics.bib
biblio-style: unified.bst
header-includes:
- \usepackage{cleveref}
fontsize: 12pt
indent: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_knit$set(root.dir = normalizePath("../../"))
library(tidyverse)
theme_set(theme_minimal())
library(tidymv)
library(rticulate)
library(mgcv)
library(itsadug)
```

```{r read-data, include=FALSE}
stimuli <- read_csv("./papers/2018-polar-gam/datasets/stimuli.csv")

columns <- c(
  "speaker",
  "seconds",
  "rec_date",
  "prompt",
  "label",
  "TT_displacement_sm",
  "TT_velocity",
  "TT_velocity_abs",
  "TD_displacement_sm",
  "TD_velocity",
  "TD_velocity_abs",
  "TR_displacement_sm",
  "TR_velocity",
  "TR_velocity_abs"
)

tongue_it01 <- read_aaa("./papers/2018-polar-gam/datasets/it01-tongue-cart.tsv", columns)  %>%
  na.omit() %>%
  mutate(word = word(prompt, 2)) %>%
  left_join(y = stimuli) %>%
  filter(X < 40, c1_phonation == "voiceless", label %in% c("max_TT", "max_TD")) %>%
  mutate(vc_voicing = interaction(vowel, c2_place, c2_phonation), vc_voicing = ordered(vc_voicing)) %>%
  mutate_if(is.character, as.factor) %>%
  arrange(rec_date, fan_line) %>%
  create_event_start("rec_date")

contrasts(tongue_it01$vc_voicing) <- "contr.treatment"

tongue_it02 <- read_aaa("./papers/2018-polar-gam/datasets/it02-tongue-cart.tsv", columns)  %>%
  na.omit() %>%
  mutate(word = word(prompt, 2)) %>%
  left_join(y = stimuli) %>%
  filter(c1_phonation == "voiceless", label %in% c("max_TT", "max_TD"), fan_line > 5, fan_line < 40) %>%
  mutate(vc_voicing = interaction(vowel, c2_place, c2_phonation), vc_voicing = ordered(vc_voicing)) %>%
  mutate_if(is.character, as.factor) %>%
  arrange(rec_date, fan_line) %>%
  create_event_start("rec_date")

contrasts(tongue_it02$vc_voicing) <- "contr.treatment"

tongue_it03 <- read_aaa("./papers/2018-polar-gam/datasets/it03-tongue-cart.tsv", columns)  %>%
  na.omit() %>%
  mutate(word = word(prompt, 2)) %>%
  left_join(y = stimuli) %>%
  filter(c1_phonation == "voiceless", label %in% c("max_TT", "max_TD"), fan_line < 40) %>%
  mutate(vc_voicing = interaction(vowel, c2_place, c2_phonation), vc_voicing = ordered(vc_voicing)) %>%
  mutate_if(is.character, as.factor) %>%
  arrange(rec_date, fan_line) %>%
  create_event_start("rec_date")

contrasts(tongue_it03$vc_voicing) <- "contr.treatment"

tongue_it04 <- read_aaa("./papers/2018-polar-gam/datasets/it04-tongue-cart.tsv", columns)  %>%
  na.omit() %>%
  mutate(word = word(prompt, 2)) %>%
  left_join(y = stimuli) %>%
  filter(c1_phonation == "voiceless", label %in% c("max_TT", "max_TD"), fan_line < 38) %>%
  mutate(vc_voicing = interaction(vowel, c2_place, c2_phonation), vc_voicing = ordered(vc_voicing)) %>%
  mutate_if(is.character, as.factor) %>%
  arrange(rec_date, fan_line) %>%
  create_event_start("rec_date")

contrasts(tongue_it04$vc_voicing) <- "contr.treatment"
```

# Introduction

<!-- need to say that tongue comes from UTI -->
Since the publication of the seminal paper by @davidson2006, statistical modelling of whole tongue contours obtained with ultrasound imaging has been dominated by the use of Smoothing Splines Analysis of Variance (SS-ANOVA, \citealt{gu2013}).
These models have greatly advanced our understanding of tongue articulation and speech modelling.
<!-- Some of the limitations of modelling tongue contours with SS-ANOVA is that separate models are needed for different phonetic contexts even within a single speaker, and that SS-ANOVA as implemented in most studies does not include random effects (for the importance of random effects in ).
The general difficulty felt with SS-ANOVA and tongue contours has favoured alternative methods like Principal Component Analysis. -->
On the other hand, developments in the statistical and programming world have seen the emergence of a highly flexible technique, Generalised Additive models (GAMs).
GAMs have being increasingly adopted in linguistics as a means to model dynamic speech data.
<!-- Indeed, @soskuthy2017 explicitly suggests the use of GAMs with tongue contours. -->
This paper introduces an implementation of GAMs with tongue contours using polar coordinates.
The use of polar GAMs is illustrated with ultrasound tongue imaging data comparing voiceless and voiced stops.
The R package `rticulate` has been developed to facilitate the use of the model, and it is briefly introduced here.

## Ultrasound tongue imaging

Ultrasound imaging is a non-invasive technique for obtaining an image of internal organs and tissue.
2D ultrasound imaging has been successfully used for imaging sections of the tongue surface (for a review and applications in field settings, see \citealt{gick2002}).
To image the tongue, the transducer placed in contact with the sub-mental triangle (the area under the chin) aligned either with the mid-sagittal or the coronal plane.
The ultrasonic waves propagate from the transducer in a radial fashion through the aperture of the mandible and get reflected when they hit the air above the tongue surface.
This 'echo' is captured by the transducer and translated into an image like that in \Cref{f:uti}.

\begin{figure}
  \centering
  \includegraphics{./img/uti.png}
  \caption{An ultrasound image of the tongue}
  \label{f:uti}
\end{figure}

## Generalised Additive models

Generalised additive modelling is a more general form of non-parametric modelling that allows fitting non-linear as well as linear effects.
Generalised additive models, or GAMs, are built with smoothing splines.
Smoothing splines are also at the heart of SS-ANOVA.
In GAMs, however, smoothing splines maximise the fit to the data while being constrained by a smoothing penalty estimated from the data itself which prevents overfitting.
GAMs are powerful and flexible models that can deal with non-linear data efficiently.
Moreover, random effects can also be implemented in GAMs, as generalised additive mixed models (or GAMMs).

Tongue contours as extracted from ultrasound imaging can be efficiently model using GAM(M)s.
The random effects part of GAMMs also constitutes an improvement over traditional SS-ANOVA, which usually implements fixed effects only.
Moreover, GAMMs can reduce autocorrelation, for example by allowing separate smooths to be fitted to the individual contours/trajectories, or by including a first-order autoregression model.
For a technical introduction to GAM(M)s, see \citet{zuur2012} and \citet{wood2017}.

## Polar coordinates

@mielke2015 and @heyne2015a, @heyne2015 have shown the benefits of using polar coordinates of the tongue contours rather then cartesian coordinates.
Polar coordinates are constituted by pairs of radius and angular values, which define a point relative to the origin of the coordinate system.
The point is describes with a radius, which corresponds to the radial distance from the origin, and the angle from the reference radius.
Tongue contours, due to their shape, tend to have increasing slope at the left and right edges, in certain cases tending to become almost completely vertical.
The almost verticality of the contours has the effect of increasing the variance of the fitted contours (and hence increased confidence intervals), and is some cases it even generates uninterpretable curves.
When tongue contours are expressed with polar coordinates, on the other hand, the variance is reduced and the fitted contours generally reflect more closely the underlying tongue shape.
Mielke has implemented a series of R [@r-core-team2018] functions for fitting polar SS-ANOVAs to tongue contours in cartesian coordinates.
Plotting is subsequently obtained by reconverting the coordinates to cartesian.

# Polar GAM(M)s

Having shown the benefits of using GAMMs with dynamic data and polar coordinates, polar GAMMs for modelling tongue contours are introduced here. Polar GAMMs are GAMMs fitted to tongue contours using polar coordinates.
As with SS-ANOVA, the coordinates of the fitted contours are converted to cartesian coordinates for plotting.
A polar GAM is constructed as follows: the radius coordinates is the outcome variable, a smooth term over the angular coordinates is the predictor.
The smooth term enables modelling the non-linearities of the contours.
Predictors such as consonant or vowel type, or speech rate, can be specified in the model.
The predicted polar coordinates that are returned by the model can then be converted to cartesian coordinates using the cartesian coordinate of the origin that defines the polar system.
The polar origin is either known or estimated from the data, depending on the ultrasonic system used.

To illustrate the use of polar GAMs, an example will given in the following sections.
The main properties of the R package `rticulate` will also be discussed in relation to the experiment.
The function `polar_gam()` accepts cartesian coordinates, which are converted into polar using a user specified origin or the origin estimated from the data.
The GAM is fitted on the polar coordinates and the predicted values are converted back to cartesian using the same origin for plotting.

## Data collection and processing

Synchronised audio and ultrasound tongue imaging data have been recorded from 4 speakers of Italian.
<!-- maybe you want to use just 4 or 5 for illustrative purposes -->
An Articulate Instruments Ltd™ set-up was used for this study (\Cref{f:uti-setup}).
The ultrasonic data was collected through a TELEMED Echo Blaster 128 unit with a TELEMED C3.5/20/128Z-3 ultrasonic transducer (20mm radius, 2-4 MHz).
A synchronisation unit (P-Stretch) was plugged into the Echo Blaster unit and used for automatic audio/ultrasound synchronisation.
A FocusRight Scarlett Solo pre-amplifier and a Movo LV4-O2 Lavalier microphone were used for audio recording.
The acquisition of the ultrasonic and audio signals was achieved with the software Articulate Assistant Advanced (AAA, v2.17.2) running on a Hawlett-Packard ProBook 6750b laptop with Microsoft Windows 7.
Stabilisation of the ultrasonic transducer was ensured by using a headset produced by Articulate Instruments Ltd™ (\citeyear{articulate2008}).

Before the reading task, the participant's occlusal plane was obtained using a bite plate [@scobbie2011].
The participants read nonce words embedded in the frame sentence *Dico \_\_\_ lentamente* 'I say \_\_\_ slowly'.
The words follow the structure C\textsubscript{1}V́\textsubscript{1}C\textsubscript{2}V\textsubscript{2}, where C\textsubscript{1} = /p/, V\textsubscript{1} = /a, o, u/, C\textsubscript{2} = /t, d, k, g/, and V\textsubscript{2} = V\textsubscript{1}.
Each speaker repeated the stimuli six times.

Spline curves were fitted to the visible tongue contours using the AAA automatic tracking function.
Manual correction was applied in those cases that showed clear tracking errors.
The time of maximum tongue displacement within consonant closure was then calculated in AAA following the method in @strycharczuk2015, described in what follows.
A fan-like frame consisting of 42 equidistant radial lines was used as the coordinate system.
The origin of the 42 fan-lines coincides with the centre of the ultrasonic probe, such that each fan-line is parallel to the direction of the ultrasonic signal.
Tongue displacement was thus calculated as the displacement of the fitted splines along the fan-line vectors.
The time of maximum tongue displacement was the time of greater displacement along the vector that showed the greatest standard deviation.
The vector search area was restricted to the portion of the splines corresponding to the tongue tip for coronal consonants, and to the portion corresponding to the tongue dorsum for velar consonants.

The cartesian coordinates of the tongue contours were extracted from the ultrasonic data at the time of maximum tongue displacement (always within C2 closure).
The contours were subsequently normalised within speaker by applying offsetting and rotation relative to the participant’s occlusal plane [@scobbie2011].
The dataset is thus constituted by *x* and *y* coordinates of the tongue contours that define respectively the horizontal and vertical axis.
The horizontal plane is parallel to the speaker's occlusal plane.

## Fitting a polar GAM

GAMMs can be fitted in R with the `gam()` function from package `mgcv` [@wood2011; @wood2017].
`bam()` is a more efficient function when the datasets has several hundreds observations.
The package `rticulate` has been developed as a wrapper of the `bam()` function to be used with tongue contours.
The special function `polar_gam()` can fit any specified GAM model to tongue contours coordinates, using the same syntax of `mgcv`.
The function accepts tongue contours either in cartesian or polar coordinates.
In the first case, the coordinates can be transformed into polar before fitting.
The function `plot_polar_smooths()`, used for plotting the estimated contours, converts the coordinates back into cartesian.

A GAM in R can be specified with a formula that uses the same syntax of `lme4`, a commonly used package for linear mixed-effects models.
The `mgcv` package allows to specify smoothing spline terms with the function `s()`.
This function takes the term along which a spline is created (for example, a time series, or *x*-coordinates).
Within `s()` the user can choose, among other arguments, what kind of spline to use, and the grouping factor (namely, the factor with the levels to be compared).
For a more in-depth introduction to GAM(M)s in R targeted to linguists, see \citet{soskuthy2017} and \citet{wieling2017}.

Due to differences in the placement of the probe and the speaker's anatomy, different portions of the tongue are likely to be imaged across speakers.
For this reason, it is recommended to fit separate models for each participant, rather then aggregate all of the data in a single model.
<!-- show the problem -->

As means of illustration, the following paragraphs will show how to fit a polar GAM with data from one of the 4 Italian speakers.

We can start from a simple model in which we test the effect of C2 place, vowel, and voicing on tongue contours.
Modelling different contours for each combination of the three predictors can be achieved with the `by` argument in the difference smooth function and including the related parametric term.
`vc_voicing` is an ordered factor which specifies for each contour the combination of C2 place, vowel, and voicing.
The following code fits the specified model to the contour data of IT01.
When running the code, the coordinates of the estimated origin used for the conversion to polar coordinates are returned.
The author can optionally specify those manually, the contours are not in a fan-like system (like the data exported from AAA).

```{r it01-gam, cache=TRUE}
it01_gam <- polar_gam(
  Y ~
    vc_voicing +            # parametric term
    s(X) +                  # reference smooth
    s(X, by = vc_voicing),  # difference smooth
  data = tongue_it01,
  method = "ML"
)
```

The function `plot_polar_smooths()` can be used to plot the estimated contours.
The shaded areas around the estimated contours are 95\% confidence intervals.
Note that, differently from SS-ANOVA, statistical significance can't be assessed from the overlapping (or lack thereof) of the confidence intervals.

```{r it01-gam-plot, include=TRUE, fig.cap = "Estimated tongue contours of IT01 depending on C2 place, vowel and C2 voicing.", fig.lp="f:", out.extra="width=\\linewidth"}
plot_polar_smooths(
  it01_gam,
  X,
  voicing,
  facet_terms = c2_place + vowel,
  # the following splits the factor interaction in the individual terms, so that
  # they can called in the plotting arguments
  split = list(vc_voicing = c("vowel", "c2_place", "voicing"))
) +
  coord_fixed() +
  theme(legend.position = "top")
```

One way of assessing significance is to compare the ML score of the full model against one without the relevant predictor, using the function `compareML()` from the `itsadug` package.
Both the parametric term and the difference smooth need to be removed in the null model.

```{r it01-gam-0, cache=TRUE}
it01_gam_0 <- polar_gam(
  Y ~
    # vc_voicing +            # remove parametric term
    s(X),                     # keep reference smooth
    # s(X, by = vc_voicing),  # remove difference smooth
  data = tongue_it01,
  method = "ML"
)
```

```{r compare-it01}
compareML(it01_gam_0, it01_gam)
```

To check which part of the contour differs among conditions, the method recomended in \citet{soskuthy2017} is to plot the difference smooth and check the confidence interval.
The parts of confidence interval that don't include 0 indicate that the difference between contours in that part is significant.

```{r diff-it01-a}
plot_difference(
  it01_gam,
  X,
  difference = list(vc_voicing = c("a.coronal.voiced", "a.coronal.voiceless"))
) + scale_x_reverse()
```

```{r diff-it01-u}
plot_difference(
  it01_gam,
  X,
  difference = list(vc_voicing = c("u.coronal.voiced", "u.coronal.voiceless"))
) + scale_x_reverse()
```

# Comparing tongue contours in voiceless and voiced stops

Mid-sagittal tongue contours at maximum tongue displacement of voiceless and voiced stops have been compared using polar GAMs.

```{r it01-gam-ar, cache=TRUE}
it01_rho <- start_value_rho(it01_gam)

it01_gam_ar <- polar_gam(
  Y ~
    vc_voicing +
    s(X) +
    s(X, by = vc_voicing),
  data = tongue_it01,
  method = "ML",
  rho = it01_rho,
  AR_start = tongue_it01$start.event
)

it01_gam_ar_0 <- polar_gam(
  Y ~
    s(X),
  data = tongue_it01,
  method = "ML",
  rho = it01_rho,
  AR_start = tongue_it01$start.event
)

compareML(it01_gam_ar_0, it01_gam_ar)
```

```{r it02-gam-ar, cache=TRUE}
it02_gam <- polar_gam(
  Y ~
    vc_voicing +
    s(X) +
    s(X, by = vc_voicing),
  data = tongue_it02,
  method = "ML"
)

it02_rho <- start_value_rho(it02_gam)

it02_gam_ar <- polar_gam(
  Y ~
    vc_voicing +
    s(X) +
    s(X, by = vc_voicing),
  data = tongue_it02,
  method = "ML",
  rho = it02_rho,
  AR_start = tongue_it02$start.event
)

it02_gam_ar_0 <- polar_gam(
  Y ~
    s(X),
  data = tongue_it02,
  method = "ML",
  rho = it02_rho,
  AR_start = tongue_it02$start.event
)

compareML(it02_gam_ar_0, it02_gam_ar)
```

```{r it03-gam-ar, cache=TRUE}
it03_gam <- polar_gam(
  Y ~
    vc_voicing +
    s(X) +
    s(X, by = vc_voicing),
  data = tongue_it03,
  method = "ML"
)

it03_rho <- start_value_rho(it03_gam)

it03_gam_ar <- polar_gam(
  Y ~
    vc_voicing +
    s(X) +
    s(X, by = vc_voicing),
  data = tongue_it03,
  method = "ML",
  rho = it03_rho,
  AR_start = tongue_it03$start.event
)

it03_gam_ar_0 <- polar_gam(
  Y ~
    s(X),
  data = tongue_it03,
  method = "ML",
  rho = it03_rho,
  AR_start = tongue_it03$start.event
)

compareML(it03_gam_ar_0, it03_gam_ar)
```

```{r it04-gam-ar, cache=TRUE}
it04_gam <- polar_gam(
  Y ~
    vc_voicing +
    s(X) +
    s(X, by = vc_voicing),
  data = tongue_it04,
  method = "ML"
)

it04_rho <- start_value_rho(it04_gam)

it04_gam_ar <- polar_gam(
  Y ~
    vc_voicing +
    s(X) +
    s(X, by = vc_voicing),
  data = tongue_it04,
  method = "ML",
  rho = it04_rho,
  AR_start = tongue_it04$start.event
)

it04_gam_ar_0 <- polar_gam(
  Y ~
    s(X),
  data = tongue_it04,
  method = "ML",
  rho = it04_rho,
  AR_start = tongue_it04$start.event
)

compareML(it04_gam_ar_0, it04_gam_ar)
```
