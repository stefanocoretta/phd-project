---
title: This is a title and this is too
shorttitle: A subtitle goes on another line
author:
- name: Stefano Coretta
  affiliation: The University of Manchester
  email: stefano.coretta\@manchester.ac.uk
  thanks: other info
output:
  jasaarticle::jasa_article:
    citation_package: natbib
abstract: |
  Put your abstract here.
bibliography: linguistics.bib
header-includes:
- \usepackage{cleveref}
- \usepackage{ctable}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lme4)
library(effects)
```

```{r read-data, include=FALSE, message=FALSE}
speakers <- read_csv("./datasets/speakers.csv")
stimuli <- read_csv("./datasets/stimuli.csv")

durations <- list.files(path = "./datasets",
                   pattern = "*-durations.csv",
                   full.names = TRUE) %>%
    map_df(~read_csv(., na = "--undefined--")) %>%
    left_join(y = speakers) %>%
    left_join(y = stimuli) %>%
    mutate_if(is.character, as.factor) %>%
    mutate(
        c2_phonation = factor(c2_phonation, levels = c("voiceless", "voiced"))
    )

durations_filtered <- durations %>%
  group_by(speaker) %>%
  mutate(
    vowel_duration_z = scale(vowel_duration),
    closure_duration_z = scale(closure_duration),
    rel_rel_z = scale(rel_rel)
  ) %>%
  filter(
    vowel_duration_z < 3, vowel_duration_z > -3,
    closure_duration_z < 3, closure_duration_z > -3,
    rel_rel_z < 3, rel_rel_z > -3
  ) %>%
  na.omit()
```

# Introduction

Almost 100 years of research have repeatedly shown that consonantal voicing has an effect on preceding vowel duration: vowels followed by voiced obstruents are longer than when followed by voiceless ones [@heffner1937; @house1953; @belasco1953; @peterson1960; @halle1967; @chen1970; @klatt1973; @lisker1974; @raphael1975; @javkin1976; @maddieson1976; @farnetani1986; @kluender1988; @laeufer1992; @fowler1992; @hussein1994; @esposito2002; @lampp2004; @warren2005; @durvasula2012].
Evidence for such so called 'voicing effect' has been found in a variety of languages, including (but not limited to) English, German, Hindi, Russian, Italian, Arabic, and Korean [see @maddieson1976 for a more comprehensive, but still not exhaustive list].
Despite of the plethora of evidence in support of the *existence* of the voicing effect, still after 100 years agreement hasn't been reached regarding the source of this effect.

Several proposal have been put forward as to where to look for the possible cause of the voicing effect.
@soskuthy2013 divides the most notable into two categories: production accounts, which ..., and perception accounts.
Since the former will prove more relevant to the present study, the latter will not be discussed.
Four main proposal within the production side of the accounts will be discussed in the following paragraphs.
Moreover, even though it is amply recognised that different manner of articulation influences the size of effect, this paper focusses on stops.

Two accounts relate the voicing effect to some constant property of speech that is held constant across contexts while the local property of voiceless vs. voiced obstruents varies, thus creating a trade-off solution within the constant property.
@belasco1953 and @delattre1962 argued that the constant property is the articulatory force, such that this force is stable within the syllable.
Since, as they go, voiceless stops require a greater articulatory force, less force is employed in the production of the vowel preceding the stop.
Such reduced force of articulation results in a shorter vowel.
Vice versa, voiced stops require less force, leaving the articulation of preceding vowels stronger.
Vowels before weakly articulated stops can be long.
The second theory, instead, argues that the relevant invariant property of speech is a constant durational interval within which segments of different duration results in different duration of other segments [@slis1969; @lehiste1970].
Both the syllable and the words has been proposed as the fixed interval.
The closure of voiced stops is shorter than that of voiceless stops.
It follows that vowels followed by shorter closures (like in the case of voiced stops) are longer than vowels followed by longer closures (like in the case of voiceless stops).

The other two accounts argue instead that the difference in vowel duration is brought about by differences in gestural timing regarding either the vocal folds (hence properties of phonation) or the consonant closing gesture (hence properties of supra-glottal articulation).
<!-- explain -->

<!-- say that none of these works with the aspiration effect -->

<!-- say offer evidence for durational trade-off account and a way of reconciling the results from M&G -->

# Method

## Speakers

## Equipment

The acquisition of the audio signal was achieved with the software Articulate Assistant Advanced™ (AAA, v2.17.2) running on a Hawlett-Packard ProBook 6750b laptop with Microsoft Windows 7, with a sample rate of 22050 MHz (16-bit) in a proprietary format.
A FocusRight Scarlett Solo pre-amplifier and a Movo LV4-O2 Lavalier microphone were used for audio recording.

## Materials

The target stimuli were disyllabic words with C\textsubscript{1}V\textsubscript{1}C\textsubscript{2}V\textsubscript{2} structure, where C\textsubscript{1} = /p/, V\textsubscript{1} = /a, o, u/, C\textsubscript{2} = /t, d, k, g/, and V\textsubscript{2} = V\textsubscript{1} (e.g. /pata/, /pada/, /poto/, etc.).
The lexical stress of the target words was placed by speakers of both Italian and Polish on V\textsubscript{1}, as intended.
The make-up of the target words was constrained by the design of the experiment, which included ultrasound tongue imaging (UTI).
Front vowels are difficult to image with UTI, since their articulation involves tongue positions which are particularly far from the ultrasonic probe, hence reducing the visibility of the tongue contour.
For this reason, only central and back vowels were included.
Since one of the variables of interest in the exploratory study was the closing gesture of C\textsubscript{2}, only lingual consonants were used.
A labial stop was chosen as the first consonant to reduce possible coarticulation with the following vowel (although see \citealt{vazquez-alvarez2007}).
The target words were embedded in a frame sentence, *Dico X lentamente* 'I say X slowly' in Italian, and *Mówię X teraz* 'I say X now' in Polish.
These sentences were chosen in order to keep the placement of stress and emphasis similar across languages, so to ensure comparability of results.

## Procedure

The participant was asked to read the sentences with the target words which were sequentially presented on the computer screen.
The order of the sentence stimuli was randomised for each participant.
Each participant read the list of randomised sentence stimuli six times.
Due to software constraints, the order of the list was kept the same across the six repetitions within each participant.
Each speaker read a total of 72 sentences, with a grand total of 576 tokens (288 per language).
The reading task lasted between 15 and 20 minutes, with optional short breaks between one repetition and the other.

## Data processing, measurements, and statistical analysis

\ctable[caption = List of measurements as extracted from acoustics.,
label = t:dur-measures,
width=\textwidth,
star
]{ll>{\raggedright}p{9cm}}{}{
\FL
\textbf{landmark}               &                  & \textbf{criteria}                                                                                    \ML
vowel onset           & (V1 onset)         & appearance of higher formants in the spectrogram following the burst of /p/ (C1)            \NN
vowel offset          & (V1 offset)        & disappearance of the higher formants in the spectrogram preceding the target consonant (C2) \NN
consonant onset       & (C2 onset)         & corresponds to V1 offset                                                                    \NN
closure onset         & (C2 closure onset) & corresponds to V1 offset                                                                    \NN
consonant offset      & (C2 offset)        & appearance of higher formants of the vowel following C2 (V2); corresponds to V2 onset                                \NN
consonant release & (C1/C2 release)         & automatic detection + manual correction \citep{ananthapadmanabha2014}                                           \LL
}

The audio recordings were exported from AAA in `.wav` format for further processing.
A forced aligned transcription was accomplished through the SPeech Phonetisation Alignment and Syllabification software (SPPAS) [@bigi2015].
The outcome of the automatic annotation was manually corrected when necessary, according to the criteria in \Cref{t:dur-measures}.
The releases of C1 and C2 were detected automatically by means of a Praat scripting implementation of the algorithm described in @ananthapadmanabha2014.
The durations in milliseconds of the following intervals were extracted from the annotated acoustic landmarks with Praat scripting: vowel duration (V1 onset to V1 offset), consonant closure duration (V1 offset to C2 burst), and C1 release to C2 release duration (Rel-Rel duration).

<!-- syllable rate as speech rate -->
<!-- INCLUDE VERSION OF R AND PACKAGES -->

The durational measurements were analysed with linear mixed-effects models using `lme4` in R [@r-core-team2017; @bates2015].
<!-- *P*-values were obtained with likelihood ratio tests comparing the full model with a nested model without the relevant predictor. -->
<!-- say lmerTest -->

<!-- show examples of segmentation -->

# Results

Only the most relevant terms will be presented.
For the others see tables and appendixes.

<!-- INCLUDE STANDARD ERROR! -->

## Vowel duration

A linear mixed-effects model was fitted with the following terms: vowel duration as the outcome variable; fixed effects for C2 voicing, C2 place of articulation, vowel identity, language, and speech rate (as syllables per second); by-speaker and by-word random intercept with by-speaker random slopes for C2 voicing.
All logical interactions were included.
According to t-tests with Satterthwaite's approximation to degrees of freedom, the following terms and interactions were significant: C2 voicing, C2 place of articulation, vowel identity, language, speech rate, the interaction between vowel and C2 voicing, and vowel and C2 place.
Vowels are 14 ms longer when followed by a voiced stop, although vowel identity enters in an interaction with C2 voicing.
The effect of voicing seems to be greater for /a/ and smaller for /u/, with /o/ having an intermediate effect.
Polish has on average shorter vowels than Italian (-25.5 ms), although the effect of voicing is estimated to be the same in both languages.
/u/ is 13.5 ms shorter when followed by a velar stop.
The effect of C2 place on /a/ and /o/ is smaller.
Speech rate has a negative effect on vowel duration, such that faster rates correlate with shorter vowel durations.

## Consonant closure duration

The same maximally specified model as with vowel duration has been fitted to consonant closure durations as the outcome variable.
The following terms and interactions were significant: C2 voicing, C2 place of articulation, vowel identity, language, and interactions between language and C2 place, language and vowel identity, C2 voicing and place, C2 voicing and vowel, and a three-way interaction between C2 voicing, place and vowel identity.
Stop closure is 15 ms shorter if the stop is voiced.
Vowel identity has an effect on closure duration in voiced stops, but not in voiceless stops, and more so in voiced velar than in voiced coronal stops: closure after /a/ is the shortest, while after /u/ is the longest, with closure after /o/ in the middle.

## Release to Release interval duration

The duration of the interval between the release of C1 and the release of C2 is not affected by C2 voicing.

# Discussion

\begin{acknowledgments}
Thanks to...
\end{acknowledgments}

\appendix
\section{Optional appendix}
