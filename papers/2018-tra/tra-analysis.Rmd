---
title: "Tongue root position"
author: "Stefano Coretta"
date: "05/12/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = normalizePath("../../"))
library(tidyverse)
theme_set(theme_minimal())
library(coretta2018itapol)
data("kinematics_series")
data("kinematics")
library(mgcv)
library(tidymv)
library(itsadug)
library(lme4)
library(lmerTest)
library(sjPlot)

tra_series <- kinematics_series %>%
  filter(c1_phonation == "voiceless", proportion > 0) %>%
  mutate(
    c2_phonation = factor(c2_phonation, levels = c("voiceless", "voiced")),
    trp = -TR_displacement_sm,
    c2_phonation_o = ordered(c2_phonation,  levels = c("voiceless", "voiced")),
    speaker_voicing = interaction(speaker, c2_phonation)
  ) %>%
  mutate_if(is.character, as.factor) %>%
  arrange(rec_date, proportion) %>%
  create_start_event(rec_date)

contrasts(tra_series$c2_phonation_o) <- "contr.treatment"

kines <- kinematics %>%
  filter(c1_phonation == "voiceless", label == "closure_", TR_displacement_sm > 10) %>%
  mutate(
    c2_phonation = factor(c2_phonation, levels = c("voiceless", "voiced")),
    trp = -TR_displacement_sm,
    v1_duration_c = v1_duration - mean(v1_duration)
  ) %>%
  mutate_if(is.character, as.factor)

kines_max <- kinematics %>%
  filter(c1_phonation == "voiceless", label %in% c("max_TT", "max_TD"), TR_displacement_sm > 10) %>%
  mutate(
    c2_phonation = factor(c2_phonation, levels = c("voiceless", "voiced")),
    trp = -TR_displacement_sm
  ) %>%
  mutate_if(is.character, as.factor)

kines_mean <- kines %>%
  group_by(speaker) %>%
  mutate(trp_z = scale(trp)) %>%
  group_by(speaker, c2_phonation, language) %>%
  summarise(
    trp_mean = mean(trp, na.rm = TRUE),
    trp_sd = sd(trp, na.rm = TRUE),
    trp_z_mean = mean(trp_z, na.rm = TRUE),
    trp_z_sd = sd(trp, na.rm = TRUE),
    n = n()
  ) %>%
  ungroup()

trp_difference <- kines_mean %>%
  group_by(speaker) %>%
  mutate(
    difference = trp_mean - lag(trp_mean),
    difference_se = sqrt( ((trp_sd^2) / n) + ((lag(trp_sd)^2) / lag(n)) )
    ) %>%
  na.omit()
```

# Plots

```{r trp-mean}
kines_mean %>%
  ggplot(aes(c2_phonation, trp_mean, colour = language)) +
  geom_point() +
  geom_line(aes(group = speaker))
```

```{r trp-mean-2}
kines_mean %>%
  ggplot(aes(c2_phonation, trp_mean, colour = language)) +
  geom_jitter(position = position_jitter(width = 0.05, height = 0, seed = 8788)) +
  geom_line(aes(group = speaker), position = position_jitter(width = 0.05, height = 0, seed = 8788))
```

```{r trp-z-mean}
kines_mean %>%
  ggplot(aes(c2_phonation, trp_z_mean, colour = language)) +
  geom_point() +
  geom_line(aes(group = speaker))
```

```{r trp-difference}
trp_difference %>%
  ggplot(aes(difference, reorder(speaker, difference), colour = language)) +
  geom_errorbarh(aes(xmin = difference - difference_se, xmax = difference + difference_se, linetype = language), height = 0) +
  geom_point(aes(shape = language), size = 4)
```

```{r trp-difference-dens}
trp_difference %>%
  ggplot(aes(difference)) +
  geom_density() +
  geom_rug()
```

```{r trp-dens}
kines %>%
  ggplot(aes(trp, fill = c2_phonation)) +
  geom_density(alpha = 0.5) +
  geom_rug()
```

```{r trp-box}
kines %>%
  ggplot(aes(c2_phonation, trp)) +
  geom_boxplot() +
  geom_jitter(width = 0.2, alpha = 0.2) +
  facet_grid(~ language)
```

```{r trp-z-box}
kines %>%
  group_by(speaker) %>%
  mutate(trp_z = scale(trp)) %>%
  ggplot(aes(c2_phonation, trp_z)) +
  geom_boxplot() +
  geom_jitter(alpha = 0.2, position = position_jitter(width = 0.2, seed = 123))
```

```{r trp-z-box}
kines %>%
  group_by(speaker) %>%
  mutate(trp_z = scale(trp)) %>%
  ggplot(aes(vowel, trp_z, fill = c2_phonation)) +
  geom_boxplot() +
  geom_point(alpha = 0.2, position = position_jitterdodge(seed = 123))
```

# Tongue root position

```{r trp-language}
tra_series %>%
  ggplot(aes(proportion, trp, colour = c2_phonation)) +
  geom_smooth() +
  facet_grid(~ language)
```

```{r trp-speakers}
tra_series %>%
  ggplot(aes(proportion, trp, colour = c2_phonation)) +
  geom_smooth(method = "loess", span = 1.5) +
  facet_wrap(~ speaker, scales = "free")
```

```{r tra-gam}
if (!file.exists("./voicing-effect/data/cache/tra-gam.Rdata")) {
  tra_gam <- bam(
    trp ~
      c2_phonation_o +
      s(speech_rate_c) +
      s(proportion) +
      s(proportion, by = c2_phonation_o) +
      ti(proportion, speech_rate_c) +
      s(proportion, speaker, bs = "fs", m = 1),
    data = tra_series
  )
  
  rho <- start_value_rho(tra_gam)
  
  tra_gam_ar <- bam(
    trp ~
      c2_phonation_o +
      s(speech_rate_c) +
      s(proportion) +
      s(proportion, by = c2_phonation_o) +
      ti(proportion, speech_rate_c) +
      s(proportion, speaker, bs = "fs", m = 1),
    data = tra_series,
    method = "ML",
    rho = rho,
    AR.start = tra_series$start_event
  )
  
  tra_gam_ar_0 <- bam(
    trp ~
      # c2_phonation_o +
      s(speech_rate_c) +
      s(proportion) +
      # s(proportion, by = c2_phonation_o) +
      ti(proportion, speech_rate_c) +
      s(proportion, speaker, bs = "fs", m = 1),
    data = tra_series,
    method = "ML",
    rho = rho,
    AR.start = tra_series$start_event
  )
  
  save(tra_gam, tra_gam_ar, tra_gam_ar_0, file = "./voicing-effect/data/cache/tra-gam.Rdata")
  
} else {
  load("./voicing-effect/data/cache/tra-gam.Rdata")
}

compareML(tra_gam_ar_0, tra_gam_ar)
```

```{r tra-gam-plot}
plot_smooths(tra_gam_ar, proportion, c2_phonation_o)
```

```{r tra-gam-plot-2}
predict_gam(tra_gam_ar, values = list(speech_rate_c = 0)) %>%
  ggplot(aes(proportion, fit)) +
  geom_smooth_ci(c2_phonation_o, size = 1) +
  facet_wrap(~ speaker, scales = "free")
```

```{r tra-gam-1}
if (!file.exists("./voicing-effect/data/cache/tra-gam-1.Rdata")) {
  tra_gam_1 <- bam(
    trp ~
      s(speech_rate_c) +
      s(proportion) +
      ti(proportion, speech_rate_c) +
      s(proportion, speaker_voicing, bs = "fs", m = 1),
    data = tra_series
  )
  save(tra_gam, tra_gam_ar, tra_gam_ar_0, file = "./voicing-effect/data/cache/tra-gam-1.Rdata")
  
} else {
  load("./voicing-effect/data/cache/tra-gam-1.Rdata")
}
```

```{r tra-gam-2}
if (!file.exists("./voicing-effect/data/cache/tra-gam-2.Rdata")) {
  tra_gam_2 <- bam(
    trp ~
      s(v1_duration) +
      s(proportion) +
      ti(proportion, v1_duration) +
      s(proportion, speaker, bs = "fs", m = 1),
    data = tra_series
  )
  
  rho <- start_value_rho(tra_gam_2)
  
  tra_gam_ar_2 <- bam(
    trp ~
      s(v1_duration) +
      s(proportion) +
      ti(proportion, v1_duration) +
      s(proportion, speaker, bs = "fs", m = 1),
    data = tra_series,
    method = "ML",
    rho = rho,
    AR.start = tra_series$start_event
  )
  
  tra_gam_ar_0_2 <- bam(
    trp ~
      s(v1_duration) +
      s(proportion) +
      # ti(proportion, v1_duration) +
      s(proportion, speaker, bs = "fs", m = 1),
    data = tra_series,
    method = "ML",
    rho = rho,
    AR.start = tra_series$start_event
  )
  
  save(tra_gam_2, tra_gam_ar_2, tra_gam_ar_0_2, file = "./voicing-effect/data/cache/tra-gam-2.Rdata")
  
} else {
  load("./voicing-effect/data/cache/tra-gam-2.Rdata")
}

compareML(tra_gam_ar_0_2, tra_gam_ar_2)
```

```{r tra-gam-2-plot}
fvisgam(
  tra_gam_ar_2,
  view = c("proportion", "v1_duration"),
  rm.ranef = TRUE
)
```

```{r tra-gam-2-smooths}
plot_smooth(tra_gam_ar_2, "proportion", cond = list(v1_duration = 50), rm.ranef = TRUE, col = "#000000", lwd = 3)
plot_smooth(tra_gam_ar_2, "proportion", cond = list(v1_duration = 100), rm.ranef = TRUE, col = "#E69F00", add = TRUE, lwd = 3) # orange
plot_smooth(tra_gam_ar_2, "proportion", cond = list(v1_duration = 145), rm.ranef = TRUE, col = "#56B4E9", add = TRUE, lwd = 3) # blue
plot_smooth(tra_gam_ar_2, "proportion", cond = list(v1_duration = 200), rm.ranef = TRUE, col = "#009E73", add = TRUE, lwd = 3) # green
```

```{r tra-gam-2-plot-2}
predict_gam(tra_gam_ar_2, exclude_terms = "s(proportion,speaker)", values = list(v1_duration = c(50, 100, 145, 200))) %>%
  filter(speaker == "it01") %>% # random effect have been cancelled, so selecting one speaker
  ggplot(aes(proportion, fit)) +
  geom_smooth_ci(v1_duration, size = 1, ci_alpha = 0.05) +
  labs(
    x = "V1 proportion",
    y = "Tongue root position (mm)"
  ) +
  scale_colour_discrete(name = "V1 duration (ms)") +
  scale_linetype_discrete(name = "V1 duration (ms)")
```

# Tongue root at closure and vowel duration

```{r v1-dur-trp}
kines %>%
  ggplot(aes(v1_duration, trp)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm") +
  facet_grid(~ language)
```

No apparent pattern from raw data.

## V1 duration ~ TRP

```{r tra-lm}
tra_lm <- lmer(
  v1_duration ~
    trp +
    speech_rate_c +
    # trp:speech_rate_c +
    vowel +
    (1 + trp|speaker) +
    (1|item),
  data = kines
)
  
summary(tra_lm)
```

```{r tra-lm-est}
plot_model(tra_lm, order.terms = 1:5)
```

```{r tra-lm-plot}
plot_model(tra_lm, type = "pred", terms = c("trp", "vowel"))
```

```{r tra-lm-plot-2}
plot_model(tra_lm, type = "pred", terms = c("trp", "speech_rate_c"))
```

## TRP ~ C2 voicing

```{r tra-lm-2}
tra_lm_2 <- lmer(
  trp ~
    c2_phonation +
    speech_rate_c +
    vowel +
    (1|speaker) +
    (1|item),
  data = kines
)

summary(tra_lm_2)
```

```{r tra-lm-2-plot}
plot_model(tra_lm_2, show.values = TRUE, show.p = FALSE, order.terms = 1:4)
```

```{r tra-lm-2-pred-plot}
plot_model(tra_lm_2, type = "pred", terms = c("c2_phonation"))
```

## TRP ~ V1 duration

```{r tra-lm-3}
tra_lm_3 <- lmer(
  trp ~
    v1_duration_c +
    speech_rate_c +
    vowel +
    v1_duration_c:vowel +
    # c2_place +
    (1+v1_duration_c|speaker) +
    (1|item),
  data = kines
)

summary(tra_lm_3)
```

```{r tra-lm-3-est}
plot_model(tra_lm_3, order.terms = 1:7)
```

```{r tra-lm-3-est-2}
plot_model(tra_lm_3, terms = "v1_duration_c")
```

```{r tra-lm-3-plot}
plot_model(tra_lm_3, type = "pred", terms = c("v1_duration_c", "vowel"))
```

## TRP ~ V1 duration and C2 voicing

```{r tra-lm-4}
tra_lm_4 <- lmer(
  trp ~
    v1_duration *
    c2_phonation +
    vowel +
    speech_rate_c +
    (1|speaker) +
    (1|item),
  data = kines
)

summary(tra_lm_4)
```

## TRP at max ~ C2 phonation

```{r tra-max-lm}
tra_max_lm <- lmer(
  trp ~
    c2_phonation +
    vowel +
    c2_place +
    (1|speaker) +
    (1|item),
  data = kines_max,
  REML = FALSE
)

summary(tra_max_lm)
```

I think that getting TRP at maximum displacement might not be sensible. TR and consonant gesture might be secluded, and maximum displacement of consonant gesture might not coincide with maximum TRA.
Including interaction `c2_phonation:language` suggest Italian and Polish behave similarly.
