---
title: "Closing gesture"
author: "Stefano Coretta"
date: "29/06/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = normalizePath("../../../"))
library(tidyverse)
theme_set(theme_bw())
library(rticulate)
library(lme4)
library(lmerTest)
library(effects)
# library(fitdistrplus)
library(simr)
scale_fill_discrete <- function(...) scale_fill_brewer(..., type = "qual")
scale_colour_discrete <- function(...) scale_colour_brewer(..., type = "qual")
```

# Data import

```{r data-import, message=FALSE}
columns <- c(
  "speaker",
  "seconds",
  "rec_date",
  "prompt",
  "label",
  "TT_displacement_sm",
  "TT_velocity",
  "TT_velocity_abs",
  "TD_displacement_sm",
  "TD_velocity",
  "TD_velocity_abs",
  "TR_displacement_sm",
  "TR_velocity",
  "TR_velocity_abs"
)

speakers <- read_csv("./voicing-effect/data/datasets/speakers.csv")
stimuli <- read_csv("./voicing-effect/data/datasets/stimuli.csv")

duration <- list.files(
  path = "voicing-effect/data/datasets/acoustics/",
  pattern = "*-durations.csv",
  full.names = TRUE
) %>%
  map_df(~read_csv(., na = "--undefined--"))

tongue <- list.files(
  path = "./voicing-effect/data/datasets/ultrasound",
  pattern = "*-tongue-cart.tsv",
  full.names = TRUE
) %>%
  read_aaa(., columns, format = "wide") %>%
  select(-(X_1:Y_42)) %>%
  mutate(word = word(prompt, 2)) %>%
  left_join(y = speakers) %>%
  left_join(y = stimuli) %>%
  mutate(
    c2_phonation = factor(c2_phonation, levels = c("voiceless", "voiced"))
  ) %>%
  mutate_if(is.character, as.factor) %>%
  filter(c1_phonation == "voiceless")

closing <- tongue %>%
  filter(label %in% c("closure_", "GONS_TD", "GONS_TT")) %>%
  select(-(TT_displacement_sm:TR_velocity_abs)) %>%
  mutate(
    label = ifelse(
      label %in% c("GONS_TT", "GONS_TD"),
      "GONS",
      "closure"
    )
  ) %>%
  spread(label, seconds) %>%
  na.omit() %>%
  mutate(
    closing_duration = (closure - GONS) * 1000
  ) %>%
  filter(closing_duration > 0) %>%
  left_join(y = duration) %>%
  mutate(
    rel_gon = (GONS - c1_rel) * 1000,
    language = recode(language, italian = "Italian", polish = "Polish"),
    syl_rate = ifelse(
      language == "Italian",
      8 / sentence_duration,
      6 / sentence_duration
    )
  )

closing_2 <- tongue %>%
  filter(label %in% c("max_TD", "max_TT", "GONS_TD", "GONS_TT")) %>%
  select(-(TT_displacement_sm:TR_velocity_abs)) %>%
  mutate(
    label = ifelse(
      label %in% c("GONS_TT", "GONS_TD"),
      "GONS",
      "max"
    )
  ) %>%
  spread(label, seconds) %>%
  na.omit() %>%
  mutate(
    closing_duration = (max - GONS) * 1000
  ) %>%
  filter(closing_duration > 0) %>%
  left_join(y = duration) %>%
  mutate(
    rel_gon = (GONS - c1_rel) * 1000
  )

tongue_root <- tongue %>%
  filter(label %in% c("max_TT", "max_TD")) %>%
  group_by(speaker) %>%
  mutate(TRA_z = -scale(TR_displacement_sm), TRA = -TR_displacement_sm) %>%
  ungroup() %>%
  select(rec_date, TR_displacement_sm, TRA, TRA_z) %>%
  inner_join(y = closing)

tongue_root_2 <- tongue %>%
  filter(label %in% c("max_TT", "max_TD")) %>%
  group_by(speaker) %>%
  mutate(TRA_z = -scale(TR_displacement_sm), TRA = -TR_displacement_sm) %>%
  ungroup() %>%
  select(rec_date, TR_displacement_sm, TRA, TRA_z) %>%
  inner_join(y = closing_2)

closing_velocity <- tongue %>%
  filter(label %in% c("peak1_TT", "peak1_TD"))
```

# Closing gesture duration

```{r}
closing %>%
  ggplot(aes(c2_phonation, closing_duration)) +
  geom_boxplot()
```


```{r}
closing %>%
    ggplot(aes(closing_duration)) +
    geom_density()
```

```{r}
closing %>%
    ggplot(aes(closing_duration)) +
    geom_histogram()
```

```{r}
closing %>%
    ggplot(aes(closing_duration, colour = c2_phonation)) +
    geom_density()
```

```{r}
closing %>%
    ggplot(aes(closing_duration, colour = c2_phonation)) +
    geom_density() +
    facet_grid(c2_place ~ vowel)
```

```{r}
closing %>%
    ggplot(aes(closing_duration, fill = c2_phonation)) +
    geom_histogram()
```

```{r}
closing %>%
    ggplot(aes(language, closing_duration, colour = c2_phonation)) +
    geom_boxplot() +
    facet_grid(vowel ~ c2_place)
```

```{r}
table(closing$c2_phonation, closing$vowel, closing$c2_place)
```

```{r}
closing %>%
  ggplot(aes(c2_place, closing_duration, colour = c2_phonation)) +
  geom_boxplot() +
  facet_wrap(~ speaker)
```

```{r}
closing_lm <- lmer(
  closing_duration ~
    c2_phonation +
    vowel +
    c2_place +
    (1+c2_phonation|speaker) +
    (1|word),
  data = closing,
  REML = FALSE
)

summary(closing_lm)
```

```{r}
plot(allEffects(closing_lm))
```

# Closing gesture duration from GONS to max

```{r}
closing_2 %>%
  ggplot(aes(closing_duration)) +
  geom_density()
```

```{r}
closing_2 %>%
  ggplot(aes(closing_duration, fill = c2_phonation)) +
  geom_density(alpha = 0.5)
```

```{r}
closing_2 %>%
  ggplot(aes(closing_duration, fill = c2_phonation)) +
  geom_density(alpha = 0.5) +
  facet_grid(. ~ c2_place)
```

```{r}
closing_2 %>%
  ggplot(aes(closing_duration, fill = c2_phonation)) +
  geom_density(alpha = 0.5) +
  facet_grid(vowel ~ c2_place)
```

```{r}
closing_2 %>%
  ggplot(aes(c2_phonation, closing_duration, fill = c2_phonation)) +
  geom_boxplot()
```

```{r}
closing_2 %>%
  ggplot(aes(c2_phonation, closing_duration, fill = c2_phonation)) +
  geom_boxplot() +
  facet_grid(c2_place ~ vowel)
```

```{r}
closing_2_lm <- lmer(
  closing_duration ~
    c2_phonation +
    (1|speaker) +
    (1|item),
  data = closing_2
)
summary(closing_2_lm)
```

```{r}
closing_2_lm <- lmer(
  closing_duration ~
    c2_phonation *
    vowel *
    c2_place +
    (1|speaker) +
    (1|item),
  data = closing_2
)
summary(closing_2_lm)
```

```{r}
plot(allEffects(closing_2_lm))
```

```{r power}
fixef(closing_2_lm)["c2_phonationvoiced"] <- 15

powerSim(closing_2_lm, fixed("c2_phonationvoiced", "t"), nsim = 100)

closing_2_lm_ex <- extend(closing_2_lm, along = "speaker", n = 40)

power_1 <- powerCurve(closing_2_lm_ex, fixed("c2_phonationvoiced", "t"), along = "speaker", nsim = 20)
plot(power_1)
```


# TRA and closing gesture duration

```{r}
tongue_root %>%
  # filter(TRA_z < 3) %>%
  ggplot(aes(TRA, closing_duration, colour = c2_phonation)) +
  geom_point() +
  geom_smooth(method = "lm") +
  facet_grid(~ language)
```

```{r}
tongue_root %>%
  filter(TRA < -20) %>%
  ggplot(aes(TRA, closing_duration, colour = c2_phonation)) +
  geom_point() +
  geom_smooth(method = "lm") +
  facet_grid(~ language, scales = "free")
```

```{r}
tongue_root %>%
  filter(TRA < -20) %>%
  ggplot(aes(TRA, closing_duration, colour = c2_phonation)) +
  geom_point() +
  geom_smooth(method = "lm")
```

```{r}
tra_closing <- lmer(
  closing_duration ~
    TRA *
    vowel *
    c2_phonation *
    language +
    (1|speaker) +
    (1|item),
  data = filter(tongue_root, TRA_z < 3),
  REML = FALSE
)
summary(tra_closing)
```

```{r}
plot(allEffects(tra_closing))
```

```{r}
tra_closing_2 <- lmer(
  closing_duration ~
    TRA *
    vowel *
    c2_phonation *
    language +
    (1|speaker) +
    (1|item),
  data = filter(tongue_root_2, TRA_z < 3),
  REML = FALSE
)
summary(tra_closing_2)
```

```{r}
plot(allEffects(tra_closing_2))
```

If you include c2 voicing, TRA has a positive effect with a similar estimate to the previous lmer model.

Tongue root position is positively correlated with closing gesture duration.

# Closing gesture velocity

```{r}
closing_velocity %>%
  filter(label == "peak1_TT") %>%
  ggplot(aes(c2_phonation, TT_velocity)) +
  geom_boxplot() +
  facet_wrap(~ speaker)
```

```{r}
closing_velocity %>%
  filter(label == "peak1_TD") %>%
  ggplot(aes(c2_phonation, TD_velocity)) +
  geom_boxplot() +
  facet_wrap(~ speaker)
```

# Timing of closing gesture onset (from release to GONS)

```{r}
closing %>%
  ggplot(aes(rel_gon)) +
  geom_density()
```

```{r}
closing %>%
  ggplot(aes(rel_gon, fill = c2_phonation)) +
  geom_density(alpha = 0.5)
```

```{r}
closing %>%
  ggplot(aes(rel_gon, fill = c2_phonation)) +
  geom_density(alpha = 0.5) +
  facet_grid(c2_place ~ vowel)
```

```{r}
closing %>%
  ggplot(aes(rel_gon, fill = c2_phonation)) +
  geom_density(alpha = 0.5) +
  facet_grid(. ~ language)
```

```{r}
closing %>%
  group_by(speaker) %>%
  mutate(rel_gon = scale(rel_gon)) %>%
  ggplot(aes(rel_gon, fill = c2_phonation)) +
  geom_density(alpha = 0.5) +
  facet_grid(. ~ language)
```

```{r}
closing %>%
  group_by(speaker) %>%
  mutate(rel_gon = scale(rel_gon)) %>%
  ggplot(aes(rel_gon, fill = c2_phonation)) +
  geom_density(alpha = 0.5)
```

```{r}
closing %>%
  group_by(speaker) %>%
  mutate(rel_gon = scale(rel_gon)) %>%
  ggplot(aes(rel_gon)) +
  geom_density()
```

```{r}
closing %>%
  group_by(speaker) %>%
  mutate(rel_gon = scale(rel_gon)) %>%
  ggplot(aes(c2_phonation, rel_gon, fill = c2_phonation)) +
  geom_boxplot()
```

```{r}
closing %>%
  group_by(speaker) %>%
  mutate(rel_gon = scale(rel_gon)) %>%
  filter(rel_gon < 3, rel_gon > -3) %>%
  ggplot(aes(c2_phonation, rel_gon, fill = c2_phonation)) +
  geom_boxplot()
```

```{r}
closing %>%
  ggplot(aes(c2_phonation, rel_gon, fill = c2_phonation)) +
  geom_boxplot() +
  facet_wrap(~ speaker)
```

```{r}
rel_gon_lm <- lmer(
  rel_gon ~
    c2_phonation *
    vowel *
    c2_place *
    language +
    syl_rate +
    (1 + c2_phonation|speaker) +
    (1|item),
  data = closing
)
summary(rel_gon_lm)
```

```{r}
plot(allEffects(rel_gon_lm))
```

```{r}
rel_gon_lm_2 <- lmer(
  rel_gon ~
    c2_phonation +
    syl_rate +
    (1 + c2_phonation|speaker) +
    (1|item),
  data = closing
)
summary(rel_gon_lm_2)
```

It looks like there is no effect of voicing on the timing on the closing gesture onset.
