---
title: "17 December 2018"
author: "Stefano Coretta"
date: "17/12/2018"
output: 
  pdf_document: 
    fig_caption: yes
    highlight: tango
    latex_engine: xelatex
    number_sections: yes
    citation_package: natbib
fontsize: 12pt
bibliography: linguistics
biblio-style: unified
mainfont: Brill
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_knit$set(root.dir = normalizePath("../../"))
library(tidyverse)
theme_set(theme_minimal())
library(mgcv)
library(itsadug)
library(tidymv)
library(akima)
library(TTR)
library(coretta2018itaegg)
library(lme4)
library(lmerTest)
library(sjPlot)
library(brms)
library(bayesplot)

scale_fill_discrete <- function(...) scale_fill_brewer(..., type = "qual")
scale_colour_discrete <- function(...) scale_fill_brewer(..., type = "qual")
```

# Stimuli for English experiment

| labial |        | velar |        |
|--------|--------|-------|--------|
| teep   | teepus | teek  | teekus |
| teeb   | teebus | teeg  | teegus |
| turp   | turpus | turk  | turkus |
| turb   | turbus | turg  | turgus |
| tarp   | tarpus | tark  | tarkus |
| tarb   | tarbus | targ  | targus |

Frame sentences:

- I'll say 'X' this Thursday
- You'll say 'X' this Monday
- She'll say 'X' this Sunday
- We'll say 'X' this Friday
- They'll say 'X' this Tuesday

## Check nonce words

```{r read-subtlex, message=FALSE, cache=TRUE}
subtlex <- read_csv("./english/simuli/subtlex.csv")
```

```{r check}
subtlex %>%
  filter(Spelling %in% c("teep","teak", "teeb", "teab", "turp", "turb", "terp", "terb", "tarp", "tarb", "teek", "teak", "teeg", "teag", "turk", "terk", "turg", "terg", "tark", "targ", "teepus", "teapus", "teebus", "teabus", "turpus", "turbus", "terpus", "terbus", "tarpus", "tarbus", "teekus", "teakus", "teegus", "teagus", "turkus", "terkus", "turgus", "tergus", "tarkus", "targus")) %>%
  select(Spelling, FreqCount, `LogFreq(Zipf)`, `LogFreqBNC(Zipf)`) %>%
  arrange(desc(FreqCount))
```

Out of 24 words stimuli, 10 appear in SUBTLEX-UK (either they are phonological matches or full matches). Two of these 10 have a log frequency > 2.5 (*Turk*, *teak*). Note that the spelling for these words would be *turk* and *teek* in the experiment.

# 3D tongue surface of [s] and [z]

```{r tongue-data, message=FALSE}
read_tongue <- function(file) {
  tibble <- read_csv(file, col_names = c("X", "Y", "Z")) %>%
    mutate(file = substr(file, 26, 43))
  
  tibble <- mutate(tibble, index = seq(1, nrow(tibble)))
  
  return(tibble)
}

stimuli <- read_csv("./italian-sz/data/stimuli.csv")

tongue <- list.files(
  path = "italian-sz/data/datasets",
  pattern = "*.csv",
  full.names = TRUE
) %>%
  map_df(~read_tongue(.)) %>%
  left_join(y = stimuli) %>%
  mutate(phone = ordered(phone, levels = c("s", "z"))) %>%
  mutate_if(is.character, as.factor) %>%
  create_event_start("file")

contrasts(tongue$phone) <- "contr.treatment"
```

```{r tongue-gam, cache=TRUE}
tongue_gam_3 <- bam(
  Z ~
    phone +
    s(X, Y) +
    s(X, Y, by = phone),
  data = tongue
)

rho <- start_value_rho(tongue_gam_3)

gam_ar <- bam(
  Z ~
    phone +
    s(X, Y) +
    s(X, Y, by = phone),
  data = tongue,
  AR.start = tongue$start.event,
  rho = rho
)
```

I recorded myself in Bloomington with the 3D ultrasound machine while uttering five tokens of sustained [s] and five tokens of sustained [z].
A single 3D frame has been extracted from each token.
The following plots show the output of a 3D GAM fitted to the tongue surfaces of [s] and [z] (tip on the right).

```{r gam-ar-plot-1, warning=FALSE}
vis.gam(gam_ar, view = c("X", "Y"), theta = 0, phi = 50, scale = FALSE, cond = list(phone = "s"), ticktype = "detailed", xlim = c(1, 13), ylim = c(3, 10), zlim = c(3, 8), main = "[s]", color = "terrain", too.far = .05)
```

```{r gam-ar-plot-2, warning=FALSE}
vis.gam(gam_ar, view = c("X", "Y"), theta = 0, phi = 50, scale = FALSE, cond = list(phone = "z"), ticktype = "detailed", xlim = c(1, 13), ylim = c(3, 10), zlim = c(3, 8), main = "[z]", color = "terrain", too.far = .05)
```

There is a deeper grove in [z] compared to [s], and some lowering/advancing of the tongue root.
Note that the tongue data have not been rotated.

## Volume increase

```{r volume, cache=TRUE}
x_min <- min(tongue$X)
x_max <- max(tongue$X)
y_min <- min(tongue$Y)
y_max <- max(tongue$Y)

# File is needed in the grid for midsagittal data (it groups by file)
grid <- expand.grid(X = seq(x_min, x_max, length = 100), Y = seq(y_min, y_max, length = 100), file = levels(tongue$file))
grid <- cbind(grid, phone = rep(rep(c("s", "z"), each = 10000), 5))

predicted <- predict(gam_ar, newdata = grid)
predicted_df <- cbind(grid, predicted) %>%
  dplyr::select(-file) %>%
  unique() %>%
  spread(phone, predicted) %>%
  mutate(
    difference = s - z
  )

sum_diff <- sum(predicted_df$difference)
volume_diff <- sum_diff * (x_max - x_min)/100 * (y_max - y_min)/100

interp_data <- interp(tongue$X, tongue$Y, tongue$Z, xo = seq(x_min, x_max, length = 100), yo = seq(y_min, y_max, length = 100), duplicate = "mean")

interp_m <- interp_data$z
interp_m <- ifelse(!is.na(interp_m), 1, 0)

predicted_df_2 <- predicted_df
predicted_df_2$mask <- as.vector(t(interp_m))

predicted_df_2 <- predicted_df_2 %>%
  mutate(diff_2 = difference * mask)

sum_diff_2 <- sum(predicted_df_2$diff_2)
volume_diff_2 <- sum_diff_2 * (x_max - x_min)/100 * (y_max - y_min)/100
```

The volume increase of [z] relative to [s] is `r round(volume_diff_2, 2)` cm\textsuperscript{3}.
This estimate is based on the predicted GAM data on a surface which corresponds to the actual imaged surface.
If I remember correctly, Steven Lulich estimated that a volume increase of 20 cm\textsuperscript{3} is ideal for maintainance of voicing in a voiced fricative.

# A Bayesian analysis of the voicing effect in pre-stress vowels (/əˈCV/)

```{r davis-data, message=FALSE}
davis1989 <- read_csv("./english/data/davis1989.csv") %>%
  gather("voice_stat", "value", voiced_mean:voiceless_sd) %>%
  separate(voice_stat, c("voice", "stat")) %>%
  spread(stat, value) %>%
  rename(v_duration =  "mean") %>%
  mutate(
    voice = factor(voice, levels = c("voiceless", "voiced")),
    speaker = as.factor(speaker),
    place = factor(place, levels = c("labial", "alveolar", "velar"))
  )
```

```{r unstr-bm, cache=TRUE}
priors <- c(
  set_prior("normal(50, 25)", class = "Intercept"),
  set_prior("normal(0, 20)", class = "b", coef = "voicevoiced"),
  set_prior("normal(0, 20)", class = "b", coef = "placealveolar"),
  set_prior("normal(0, 20)", class = "b", coef = "placevelar"),
  set_prior("normal(0, 25)", class = "sd")
)

unstr_bm <- brm(
  v_duration | se(sd) ~ voice + place + (1| speaker),
  data = davis1989,
  family = gaussian(),
  prior = priors,
  cores = 4,
  seed = 1989,
  control = list(adapt_delta = 0.99)
)
```

\citet{davis1989} report means and standard deviations of the duration of reduced unstressed vowels followed by a voiceless or a voiced stop (*atop*/*adopt*).
We can use a Bayesian measurement error model which takes into account the standard deviation of the vowel durations (since we don't have the individual data points that make up the means).
The data is based on three speakers, the consonant following the reduced vowel can be labial, alveolar, or velar.
A model was fitted to vowel duration (and standard deviation) with the following predictors: C2 voicing (voiceless vs. voiced), C2 place of articulation (labial vs. alveolar vs. velar), and a by-speaker random intercept.
The following weakly informative priors have been used: a normal distribution for the intercept with mean 50 and SD = 25, a normal distribution with mean 0 and SD = 20 for the estimates of C2 voicing and C2 place, and a normal distribution with mean 0 and SD = 25 for the by-speaker random intercept.

```{r unstr-summary}
summary(unstr_bm, prob = 0.9)
```

The estimated effect of voicing is 6.32 ms with a 90\% credible interval 1.37-11.22 ms.
A credible interval idicates the range of values within which there is a given probability of finding the true estimate (a 90\% credible interval says in which range there is a 90\% probabilty that the true effect is contained within that interval).
The following plot shows the posterior distributions of C2 voicing and place (the shaded areas are 90\% credible intervals).
The posterior distribution of the predictor C2 voicing suggest a small positive effect of voicing on unstressed vowel duration.

```{r unstr-bm-areas}
mcmc_areas(as.array(unstr_bm), pars = c("b_voicevoiced", "b_placealveolar", "b_placevelar"), prob = 0.9)
```

# Italian EGG: vowel and voicing duration

```{r egg-data, message=FALSE}
data("ita_egg")
ita_egg <- ita_egg %>%
  mutate(
    vowel = factor(vowel, levels = c("a", "o", "e", "i", "u")),
    height = factor(height, levels = c("low", "mid-low", "mid-high", "high")),
    c1_place = factor(c1_place, levels = c("labial", "coronal", "velar")),
    c2_place = factor(c2_place, levels = c("labial", "coronal", "velar")),
    von_von = (v1_ons - voice_ons) * 1000
  ) %>%
  mutate_if(is.character, as.factor)
```

This section briefly reports the results from the EGG study on voicing duration and vowel height in Italian.
The following figures show the duration of vowels by vowel height, and the duration of voicing coresponding to the vowel by vowel height.
The stimuli (/ˈCVCo/) contained only voiceless stops, and voicing refers to the voicing of the vowel flanked by singleton voiceless stops.
Vowel durations decrease with vowel height.
The vowels are: low /a/, mid-low /ɔ/, mid-high /e/, high /u, i/.
Voicing durations also decrease with vowel height, possibly with the exeption of the mid-low vowel (/ɔ/), which has a voicing duration similar to the low vowel (/a/).
Two linear-mixed models have been fitted to vowel duration and voicing duration.
The general pattern is that voicing duration decreases by a smaller degree than vowel duration with increasing vowel height.
Also, non-low vowels have longer voicing during the closure of the consonant following the vowel, compared to the low vowel /a/.

```{r vow-height-box, warning=FALSE}
ita_egg %>%
  ggplot(aes(height, v1_duration, fill = height)) +
  geom_boxplot() +
  geom_jitter(alpha = 0.05, width = 0.3) +
  labs(
    title = "Vowel duration by vowel height",
    x = "Vowel height",
    y = "V1 duration (ms)"
  )
```

```{r voi-height-box, warning=FALSE}
ita_egg %>%
  ggplot(aes(height, voice_duration, fill = height)) +
  geom_boxplot() +
  geom_jitter(alpha = 0.05, width = 0.3) +
  labs(
    title = "Voicing duration by vowel height",
    x = "Vowel height",
    y = "V1 voicing duration (ms)"
  )
```

```{r vowel-lm}
vowel_lm <- lmer(
  v1_duration ~
    height +
    c2_place +
    height:c2_place +
    speech_rate_c +
    (1|speaker) +
    (1|word),
  data = ita_egg,
  control = lmerControl(optimizer = "Nelder_Mead")
)
summary(vowel_lm)
```

```{r voice-lm, echo=TRUE}
voice_lm_1 <- lmer(
  voice_duration ~
    height +
    c2_place +
    height:c2_place +
    speech_rate_c +
    (1+height|speaker) +
    (1|word),
  data = ita_egg,
  REML = FALSE
)
summary(voice_lm_1)
```

